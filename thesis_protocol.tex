\documentclass[10pt,letterpaper,final]{article}
\usepackage[left=4cm,rigth=4cm,top=4cm,bottom=2cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{kpfonts}
\usepackage{tabularx}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{colortbl}
\usepackage{tikz}
%\newcommand{\X}{\multicolumn{1}{|c|}{$\times$}}


\begin{document}
    \title{Sistema de Detección y Evasión de Colisiones basado en Visión Computacional para Vehículos Autónomos}
    \author{Rubén Martínez González}
    \maketitle
    \clearpage
    \section*{Introducción}
    \noindent
    El avance continuo en la tecnología de vehículos autónomos representa un logro significativo en la revolución del transporte.
    Existe la necesidad de desarrollar sistemas ``inteligentes'' que permitan a estos vehículos aprender a conducir de manera autónoma y,
    al mismo tiempo, detectar posibles colisiones y reaccionar de manera similar a como lo haría un conductor humano.
    La convergencia de la inteligencia artificial, la visión computacional y los sistemas de control ha generado una nueva era en la movilidad,
    desafiando y redefiniendo las fronteras de la conducción convencional.\\ \newline
    En este contexto, este trabajo se centra en el desarrollo de un sistema de detección y evasión de colisiones basado en visión computacional.
    Si bien los avances en la conducción autónoma han sido significativos, la detección y respuesta a
    situaciones de peligro, como colisiones inminentes, siguen siendo un desafío complejo.\\ \newline
    La seguridad en la carretera y la confianza del público en esta tecnología dependen en gran medida de la capacidad
    de los vehículos autónomos para enfrentar situaciones de tráfico de manera eficiente y segura.\\ \newline
    Esta investigación busca abordar esta problemática crítica, avanzando hacia un futuro en el que los vehículos autónomos
    sean capaces de igualar e incluso superar las habilidades de conducción humana en términos de detección y respuesta
    a situaciones de colisión.
    \clearpage
    
    \section*{Contexto y problemática}
    \noindent En la constante evolución de la movilidad, los vehículos autónomos representan una innovación trascendental.
    No obstante, el desafío primordial reside en dotar a estos vehículos con la capacidad de identificar y reaccionar ante situaciones de riesgo
    de manera precisa y oportuna. La detección temprana de posibles colisiones, amenazas viales y transgresiones graves a las normativas de tráfico
    es un aspecto esencial para garantizar la seguridad y la eficacia de estos sistemas autónomos. La visión computacional,
    utilizando las cámaras de video y sensores, se presenta como una estrategia central para esta detección,
    pero aún persisten desafíos tecnológicos significativos en la identificación y procesamiento oportuno de dichos eventos.
    
    \section*{Preguntas de investigación}
    \begin{itemize}
        \item ¿Cómo se puede implementar un sistema de detección y evasión de colisiones basado en visión computacional para vehículos autónomos?
        \item ¿Cómo se puede mejorar la precisión y la velocidad de detección de posibles colisiones mediante técnicas avanzadas de visión computacional?
        \item ¿Cuál es el impacto de la integración de múltiples sensores en la detección y evasión de colisiones para vehículos autónomos?
    \end{itemize}
    
    \section*{Hipótesis}
    \("\)El desarrollo de un sistema de detección y evasión de colisiones basado en visión computacional en vehículos autónomos
    proporcionará a estos la capacidad de anticipación y respuesta ante posibles situaciones de riesgo\("\)
    
    \section*{Objetivos}
    \noindent{Objetivo general:}
    \newline
    \noindent Desarrollar un sistema de detección y evasión de colisiones basado en visión computacional para vehículos autónomos en simulación.
    \newline
    \newline
    \noindent{Objetivos específicos:}
    \begin{itemize}
        \item Modelar un ambiente de simulación donde un vehiculo circule por calles transitadas.
        \item Obtener datos de los sensores del vehiculo en simulación.
        \item Interpretar los datos de los sensores mediante técnicas de visión computacional.
        \item Procesar los datos y aprender a reaccionar.
    \end{itemize}
    \clearpage
    \section*{Estado del arte - Trabajos previos relacionados}
    \newline
    \begin{longtable}
        \hline
        \newline
        \noindent La referencia bibliográfica~\cite{bachute2021autonomous} aborda el tema de las arquitecturas de conducción autónoma
        en el artículo titulado:                                                                                                          \\ \textbf{"Autonomous Driving Architectures: Insights of Machine Learning and Deep Learning Algorithms"}
        publicado en la revista Machine Learning with Applications en el año 2021.                                                        \\
        El artículo proporciona una visión general de la aplicación de algoritmos de Aprendizaje Automático y Aprendizaje Profundo
        en sistemas de conducción autónoma, destacando su evaluación en tareas cruciales. \\
        Se destaca el creciente impulso en la investigación de la conducción autónoma debido a sus ventajas inherentes, como la reducción
        de la intervención humana y la disociación del conductor del vehículo. Se subraya la complejidad de estos sistemas,
        que involucra la integración de múltiples subsistemas, y se analizan diversas tareas específicas dentro de la conducción autónoma,
        como la planificación de movimiento, la detección de peatones y señales de tráfico, el estacionamiento automatizado, entre otras.\\
        El estudio se centra en la aplicación de algoritmos de Aprendizaje Automático y Aprendizaje Profundo para abordar estas tareas,
        evaluando y comparando su rendimiento a través de métricas específicas. La investigación ofrece una perspectiva amplia sobre el uso
        y la evaluación de estos algoritmos en el contexto de la conducción autónoma.
        
        \begin{figure}[!ht]
            \begin{subfigure}
                \includegraphics[width=0.5\textwidth]{img/12Screenshot_20231106_142954}\label{fig:12}
            \end{subfigure}
            \begin{subfigure}
                \includegraphics[width=0.5\textwidth]{img/13Screenshot_20231106_143018}\label{fig:13}
            \end{subfigure}
            \begin{subfigure}
                \includegraphics[width=0.5\textwidth]{img/15Screenshot_20231106_143633}\label{fig:15}
            \end{subfigure}
            \begin{subfigure}
                \includegraphics[width=0.5\textwidth]{img/14 Screenshot_20231106_143419}\label{fig:14}
            \end{subfigure}
            \begin{subfigure}
                \includegraphics[width=0.99\textwidth]{img/16Screenshot_20231106_143701}\label{fig:16}
            \end{subfigure}
        \end{figure}
        \clearpage
        
        \hline
        \noindent La referencia bibliográfica~\cite{cai2021vision} presenta un estudio titulado:\\
        \textbf{"Vision-based autonomous car racing using deep imitative reinforcement learning"}
        publicado en IEEE Robotics and Automation Letters en el año 2021.                                                                 \\ El artículo aborda el desafío del automovilismo autónomo
        en el campo del control robótico, históricamente dependiente de mapas precisos, localización y planificación, lo que lo hace
        computacionalmente ineficiente y sensible a cambios en el entorno.                                                                \\
        Se destaca el desarrollo de sistemas de aprendizaje profundo de extremo a extremo, que muestran resultados prometedores en la conducción
        autónoma.                                                                                                                         \\ Sin embargo, estos sistemas suelen basarse en aprendizaje por imitación supervisada (IL), enfrentando problemas de discrepancia
        en la distribución de datos.                                                                                                      \\ Aunque se han empleado métodos de aprendizaje por refuerzo (RL), requieren grandes cantidades de datos de interacción riesgosa.
        \\ El artículo presenta un enfoque innovador denominado aprendizaje profundo imitativo y de refuerzo (DIRL), que logra la agilidad en
        el automovilismo autónomo mediante el uso de entradas visuales.                                                                              \\
        Este enfoque combina el conocimiento adquirido tanto del aprendizaje por imitación como del aprendizaje basado en modelos de RL,
        permitiendo al agente aprender de instructores humanos y mejorar su rendimiento interactuando con un modelo de mundo offline.
        La validación del algoritmo se lleva a cabo tanto en simulaciones de conducción de alta fidelidad como en un automóvil RC a escala 1/20 en
        el mundo real, con capacidad computacional limitada. \\
        Los resultados de la evaluación demuestran que este método supera a enfoques anteriores de IL y RL en eficiencia de muestra y rendimiento
        en la tarea, mostrando un gran potencial en el ámbito de la conducción autónoma.                                                                                             \\
        \begin{figure}[!ht]
            \begin{subfigure}
                \includegraphics[width=\textwidth]{img/21}\label{fig:21}
            \end{subfigure}
            \begin{subfigure}
                \includegraphics[width=\textwidth]{img/22}\label{fig:22}
            \end{subfigure}
%            \begin{subfigure}
%                \includegraphics[width=0.2\textwidth]{img/23}\label{fig:23}
%            \end{subfigure}
        \end{figure}

%        \begin{minipage}{0.5\textwidth}
%            \includegraphics[width=\textwidth]{img/23}
%        \end{minipage}
%        \begin{minipage}{0.5\textwidth}
%            Rendimiento de conducción del coche.\\
%            (a) Se toma el punto A en la trayectoria para el análisis y los relacionados
%            Los ensueños se muestran en la fila inferior con imágenes futuras reales para
%            comparación. Tenga en cuenta que los ensueños no se obtienen durante las pruebas, sino que son posteriores.
%            renderizado con observaciones actuales y acciones de bucle abierto.\\
%            (b) El planificado acciones de circuito abierto (planificadas por la red de políticas en cada paso, pero solo el
%            se ejecutará el primero) en el punto A y acciones de bucle cerrado relacionadas (el
%            acciones realmente ejecutadas registradas por el coche).
%        \end{minipage}
        
        \clearpage
        \hline
        \noindent La referencia bibliográfica~\cite{althoff2009model} titulada:\\
        \textbf{"Model-based probabilistic collision detection in autonomous driving"}
        escrito por Althoff, Matthias, Stursberg, Olaf y Buss en 2009 y publicado en la revista IEEE Transactions on Intelligent Transportation Systems,
        se centra en la seguridad vial de los vehículos autónomos en entornos de tráfico complejo.                                                                                                     \\
        Su enfoque principal es la detección probabilística de colisiones mediante el análisis y la predicción de la ocupación de la carretera
        por parte de otros vehículos.\\
        El estudio aborda la incertidumbre inherente en la interacción entre los vehículos autónomos y otros actores del tráfico.
        Analiza cómo las mediciones y los posibles comportamientos de estos afectan la predicción de posibles colisiones.
        Además, considera las limitaciones en las maniobras de conducción debidas a la geometría de la carretera y la influencia
        de estas restricciones en la probabilidad de colisión para trayectorias específicas.\\
        Lo más destacado de este enfoque es su eficiencia. La mayor parte de los cálculos intensivos se llevan a cabo offline,
        permitiendo disponer de un algoritmo en línea eficiente para aplicaciones en tiempo real.                                                                           \\
        Esto contribuye significativamente a la seguridad vial al proporcionar una herramienta precisa y eficaz para la detección anticipada de
        posibles colisiones en entornos de conducción autónoma.                                                            \\
        \begin{figure}[!ht]
            \begin{subfigure}
                \includegraphics[width=0.5\textwidth]{img/31}\label{fig:31}
            \end{subfigure}
            \begin{subfigure}
                \includegraphics[width=0.5\textwidth]{img/35}\label{fig:35}
            \end{subfigure}
%            \begin{subfigure}
%                \includegraphics[width=0.5\textwidth]{img/32}\label{fig:32}
%            \end{subfigure}
            \vspace{2cm}
            \begin{subfigure}
                \includegraphics[width=0.5\textwidth]{img/33}\label{fig:33}
            \end{subfigure}
            \begin{subfigure}
                \includegraphics[width=0.5\textwidth]{img/34}\label{fig:34}
            \end{subfigure}
        
        \end{figure}
        \clearpage
        
        \hline
        \noindent La referencia bibliográfica~\cite{pavel2022vision} titulada:\\
        \textbf{"Vision-based autonomous vehicle systems based on deep learning: A systematic literature review"}
        de Pavel, Monirul Islam, Tan, Siok Yee y Abdullah, Azizi, publicada en 2022 en la revista Applied Science                                                                            \\
        Se presenta una revisión sistemática de la literatura sobre el empleo de técnicas de aprendizaje profundo en los sistemas
        de vehículos autónomos a lo largo de la última década.                                                                    \\Esta revisión se divide en varios módulos que abarcan distintos aspectos,
        desde el análisis de percepción y la toma de decisiones hasta el control, la planificación de trayectorias
        y la visualización en sistemas de realidad aumentada tipo HUD.                                                                                                                   \\
        Se examinan investigaciones llevadas a cabo entre 2011 y 2021 que se enfocan en la utilización de cámaras RGB como sensores principales
        en estos sistemas. Se otorga especial atención a los resultados finales, destacando la visualización en sistemas de realidad aumentada
        basados en HUD.                                                                                                      \\Esto incluye advertencias tempranas, marcadores en la carretera para mejorar la navegación y la seguridad, superposición
        de información en vehículos y peatones en condiciones visuales extremas para reducir colisiones.
        La revisión subraya los métodos actuales de aprendizaje profundo que se basan únicamente en la visión de cámaras RGB, prescindiendo de la
        compleja fusión de sensores.                                                                     \\Se espera que este enfoque allane el camino para el desarrollo ágil de sistemas de vehículos autónomos,
        siendo prácticos, eficientes y seguros en términos de costos.                                                               \\
        \begin{figure}[!ht]
            \begin{subfigure}
                \includegraphics[width=1\textwidth]{img/71}\label{fig:71}
            \end{subfigure}
%            \begin{subfigure}
%                \includegraphics[width=0.5\textwidth]{img/72}\label{fig:72}
%            \end{subfigure}
            \begin{subfigure}
                \includegraphics[width=0.5\textwidth]{img/73}\label{fig:73}
            \end{subfigure}
            \begin{subfigure}
                \includegraphics[width=0.5\textwidth]{img/74}\label{fig:74}
            \end{subfigure}
        \end{figure}
%        \begin{figure}[!ht]
%            \begin{subfigure}
%                \includegraphics[width=1\textwidth]{img/75}\label{fig:75}
%            \end{subfigure}
%            \begin{subfigure}
%                \includegraphics[width=1\textwidth]{img/76}\label{fig:76}
%            \end{subfigure}
%        \end{figure}
        \clearpage
        
        \hline
        \noindent La referencia bibliográfica~\cite{alam2022cost} titulada:                                                        \\
        \textbf{"A cost-effective computer vision-based vehicle detection system"}                                                                                               \\
        de Alam, Altaf, Jaffery, Zainul Abdin y Sharma, Himanshu, publicado en 2022 en la revista Concurrent Engineering,Se enfoca en la detección de vehículos.
        \\Destaca la importancia crítica del procesamiento rápido y la detección precisa de vehículos dentro de un sistema autónomo de detección.
        \\Presenta un sistema de detección de vehículos basado en visión por computadora que utiliza un algoritmo de Gentle Adaptive Boosting
        con características tipo Haar para generar hipótesis de vehículos de manera eficiente.
        Para abordar los errores potenciales, propone el uso de un algoritmo de Máquinas de Vectores de Soporte (SVM) entrenado con características
        del histograma de gradientes orientados (HOG) para filtrar las hipótesis falsas.
        \\El descriptor HOG se centra en la forma y contornos de los vehículos, mejorando la precisión de la detección.
        La combinación de características tipo Haar y HOG permite cumplir los objetivos de detección en la conducción autónoma.
        \\El rendimiento del sistema propuesto se evalúa con imágenes capturadas durante el día y la noche y se compara con tres detectores
        de vehículos existentes. Los resultados muestran una precisión promedio del 0.97 para imágenes capturadas durante el día
        y del 0.94 para imágenes nocturnas.                                                                                               \\Además, se destaca que el sistema propuesto requiere aproximadamente 15 veces menos tiempo
        de entrenamiento en comparación con las técnicas existentes, utilizando la misma cantidad de datos de imágenes y la misma unidad
        de procesamiento central (CPU). Esto demuestra una mejora significativa en la eficiencia del sistema propuesto en términos de tiempo de entrenamiento.
        \begin{figure}[!ht]
%            \begin{subfigure}
%                \includegraphics[width=0.6\textwidth]{img/81}\label{fig:81}
%            \end{subfigure}
%            \begin{subfigure}
%                \includegraphics[width=0.5\textwidth]{img/86}\label{fig:82}
%            \end{subfigure}
            \begin{subfigure}
                \includegraphics[width=0.5\textwidth]{img/84}\label{fig:84}
            \end{subfigure}
            \begin{subfigure}
                \includegraphics[width=0.5\textwidth]{img/82}\label{fig:86}
            \end{subfigure}
        \end{figure}
        \clearpage
    \end{longtable}
    
    \centering
    \section*{Tabla comparativa}
    \begin{center}
        \resizebox{\textwidth}{!}{
            \begin{tabular}{|p{5cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
                \hline
                \textbf{Características}
                & \textbf{Propia}
                & \textbf{Autonomous Driving Architectures \cite{bachute2021autonomous}}
                & \textbf{Vision-based Autonomous Car Racing \cite{cai2021vision}}
                & \textbf{Model-based Probabilistic Collision Detection \cite{althoff2009model}}
                & \textbf{Vision-based Autonomous Vehicle Systems \cite{pavel2022vision}}
                & \textbf{Cost-effective Vehicle Detection System \cite{alam2022cost}} \\
                \hline
                Uso de algoritmos de Aprendizaje Automático y Aprendizaje Profundo & X & X &   &   & X &   \\
                \hline
                Enfoque en la conducción autónoma                                  & X & X & X & X & X & X \\
                \hline
                Ventajas de la conducción autónoma                                 & X & X &   &   &   &   \\
                \hline
                Complejidad de los sistemas de conducción autónoma                 &   & X &   &   &   &   \\
                \hline
                Análisis de tareas en la conducción autónoma                       & X & X &   &   &   &   \\
                \hline
                Evaluación y comparación de algoritmos                             &   & X & X &   &   &   \\
                \hline
                Predicción estocástica de ocupación de la carretera                &   &   &   & X &   &   \\
                \hline
                Eficiencia en cálculos intensivos                                  &   &   & X & X &   &   \\
                \hline
                Utilización de cámaras RGB como sensores principales               & X &   & X &   & X &   \\
                \hline
                Detección de vehículos en conducción autónoma                      & X &   &   &   &   & X \\
                \hline
            \end{tabular}
        }
    \end{center}
    \clearpage
    
    \section*{Metodología}
    \noindent La metodología propuesta se fundamenta en un enfoque iterativo que abarca diversas etapas para la implementación del sistema de detección
    y evasión de colisiones en vehículos autónomos. En primera instancia, se establecerá un entorno de simulación realista que refleje las condiciones de tráfico habituales.
    Posteriormente, se procederá a la adquisición y procesamiento de datos provenientes de los sensores de dicho entorno simulado. La fase siguiente implicará el diseño
    y la implementación de algoritmos de visión computacional para la detección temprana de eventos críticos en tiempo real. Estos algoritmos serán sometidos a un proceso
    de entrenamiento y ajuste utilizando técnicas de aprendizaje automático. Finalmente, se llevarán a cabo pruebas exhaustivas y evaluaciones para validar la efectividad
    y la precisión del sistema propuesto en situaciones simuladas de riesgo vial.
    
    \section*{Calendario de actividades}
    \begin{center}
        \resizebox{\textwidth}{!}{
            \begin{tabular}{|p{3cm}|*{17}{p{1cm}|}}
                \hline
                \textbf{Actividad} & \multicolumn{17}{c|}{\textbf{Duración}} \\
                \hline
                & Ene & Feb & Mar & Abr & May & Jun & Jul & Ago & Sep & Oct & Nov & Dic
                & Ene & Feb & Mar & Abr & May \\
                \hline
                Investigación Preliminar                    & \cellcolor{gray!30} & \cellcolor{gray!30} &                     &                     &                     &                     &                     &                     &                     &                     &                     &                     &                     &                     &                     &                     &                     & \\
                \hline
                Diseño y Configuración del Entorno Simulado &                     & \cellcolor{gray!30} & \cellcolor{gray!30} & & & & & & & & & & & & & & & \\
                \hline
                Adquisición y Procesamiento de Datos        &                     &                     &                     & \cellcolor{gray!30} & \cellcolor{gray!30} & \cellcolor{gray!30} & & & & & & & & & & & & \\
                \hline
                Desarrollo y Entrenamiento de Algoritmos    &                     &                     &                     &                     & \cellcolor{gray!30} & \cellcolor{gray!30} & \cellcolor{gray!30} & & & & & & & & & & & \\
                \hline
                Evaluación y Ajuste del Sistema             &                     &                     &                     &                     &                     & \cellcolor{gray!30} & \cellcolor{gray!30} & \cellcolor{gray!30} & & & & & & & & & & \\
                \hline
                Documentación y Análisis de Resultados      &                     &                     &                     &                     &                     &                     &                     & \cellcolor{gray!30} & \cellcolor{gray!30} & \cellcolor{gray!30} & & & & & & & & \\
                \hline
                Redacción y Presentación de la Tesis        &                     &                     &                     &                     &                     &                     &                     &                     &                     &                     & \cellcolor{gray!30} & \cellcolor{gray!30} & \cellcolor{gray!30} & \cellcolor{gray!30} & \cellcolor{gray!30} & \cellcolor{gray!30} & \cellcolor{gray!30} & \\
                \hline
            \end{tabular}
        }
    \end{center}
    \clearpage
    \section*{Referencias bibliográficas}
    \bibliographystyle{acm}
    \bibliography{referecias}
\end{document}
